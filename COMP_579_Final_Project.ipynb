{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhongjie-wu/579project/blob/main/COMP_579_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4kEEcmUGxY-"
      },
      "source": [
        "# COMP 579 Final Project: Multi-Agent Reinforcement Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHWift7bH6Vt"
      },
      "outputs": [],
      "source": [
        "# download libraries\n",
        "! pip install pettingzoo[mpe]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3acgKZwG9Nu"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "from pettingzoo.mpe import simple_speaker_listener_v3, simple_reference_v2, simple_world_comm_v2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7GYFhILDrpZ"
      },
      "source": [
        "## Individual Q-learning (Simple Speaker Listener)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper methods\n",
        "def listener_bin_init(bounds = [(-2, 2),(-4, 4)], step_size=0.05):\n",
        "    '''\n",
        "    (x_vel, y_vel, land1_x, land1_y, land2_x, land2_y, land3_x, land3_y, spearker_cmd0, spearker_cmd1, spearker_cmd2)\n",
        "    '''\n",
        "    discretized_state = [0 for i in range(8)]\n",
        "    for i in range(2):\n",
        "        discretized_state[i] = np.linspace(bounds[0][0], bounds[0][1], int((bounds[0][1] - bounds[0][0])/step_size) + 1)\n",
        "        \n",
        "    for i in range(2, 8):\n",
        "        discretized_state[i] = np.linspace(bounds[1][0], bounds[1][1], int((bounds[1][1] - bounds[1][0])/step_size) + 1)\n",
        "\n",
        "    return tuple(discretized_state)\n",
        "\n",
        "def listener_encode_state(observation, discretized_state=listener_bin_init()):\n",
        "    # encode x,y velocity\n",
        "    index = np.zeros(8)\n",
        "    result = []\n",
        "    for i in range(8):\n",
        "        idx = np.digitize([observation[i]], discretized_state[i])\n",
        "        index[i] = idx - 1\n",
        "        if i < 2:\n",
        "            result += [1 if i == idx else 0 for i in range(81)]\n",
        "        else:\n",
        "            result += [1 if i == idx else 0 for i in range(161)]\n",
        "    for i in range(8, 11):\n",
        "        result.append(observation[i])\n",
        "    return np.array(result)\n",
        "\n",
        "def speaker_encode_state(observation):\n",
        "    return np.array([float(i == np.argmax(observation)) for i in range(len(observation))])\n",
        "\n",
        "def weight_init(size: tuple):\n",
        "    return np.random.uniform(-0.001, 0.001, size)\n",
        "\n",
        "def eps_greedy_act_selection(epsilon, w, state):\n",
        "    num_choices = w.shape[0]\n",
        "    if np.random.random() < epsilon:\n",
        "        return np.random.randint(0, num_choices)\n",
        "    else:\n",
        "        result = np.dot(w, state)\n",
        "        return np.argmax(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "B4GRVuyzDrMH"
      },
      "outputs": [],
      "source": [
        "# Returns a initialized weight vector with 0\n",
        "def q_learning_sl(alpha, gamma, epsilon, num_episode, env):\n",
        "    w_speaker = weight_init((3, 3))\n",
        "    w_listener = weight_init((5, 1131))\n",
        "    R = 0\n",
        "    \n",
        "    for i in range(num_episode):\n",
        "        env.reset()\n",
        "        S_speaker = env.observe('speaker_0')\n",
        "        # encode speaker state\n",
        "        phi_speaker = speaker_encode_state(S_speaker)\n",
        "        \n",
        "        S_listener = env.observe('listener_0')\n",
        "        # encode listener state\n",
        "        phi_listener = listener_encode_state(S_listener)        \n",
        "        \n",
        "        S_next_speaker = None\n",
        "        phi_next_speaker = None\n",
        "        \n",
        "        S_next_listener = None\n",
        "        phi_next_listener = None\n",
        "        \n",
        "        for agent in env.agent_iter():\n",
        "            if agent == 'speaker_0':\n",
        "                if env.truncations[agent] == True or env.terminations[agent] == True:\n",
        "                    env.step(None)\n",
        "                    continue\n",
        "                \n",
        "                A = eps_greedy_act_selection(epsilon, w_speaker, phi_speaker)\n",
        "                # A = env.action_space(agent).sample()\n",
        "                \n",
        "                env.step(A) \n",
        "                _, R, termination, truncation, info = env.last()\n",
        "                \n",
        "                S_next_speaker = env.observe(agent)\n",
        "                phi_next_speaker = speaker_encode_state(S_next_speaker)\n",
        "                q_S_w = np.dot(w_speaker, phi_speaker)\n",
        "                q_S_A_w = q_S_w[A]\n",
        "                grad_q_S_A_w = phi_speaker\n",
        "\n",
        "                if termination or truncation:\n",
        "                    w_speaker[A] = w_speaker[A] + alpha * (R - q_S_A_w) * grad_q_S_A_w\n",
        "                    continue\n",
        "\n",
        "                max_q_S_A_w = np.max(np.dot(w_speaker, phi_next_speaker))\n",
        "                w_speaker[A] = w_speaker[A] + alpha * (R + gamma*max_q_S_A_w - q_S_A_w) * grad_q_S_A_w\n",
        "                phi_speaker = phi_next_speaker\n",
        "                \n",
        "                # for debug usage\n",
        "                S_speaker = S_next_speaker\n",
        "                \n",
        "            else:\n",
        "                if env.truncations[agent] == True or env.terminations[agent] == True:\n",
        "                    env.step(None)\n",
        "                    continue\n",
        "                \n",
        "                A = eps_greedy_act_selection(epsilon, w_listener, phi_listener)\n",
        "                # A = env.action_space(agent).sample()\n",
        "\n",
        "                env.step(A)\n",
        "\n",
        "                _, R, termination, truncation, info = env.last()\n",
        "\n",
        "                S_next_listener = env.observe(agent)\n",
        "                phi_next_listener = listener_encode_state(S_next_listener)\n",
        "\n",
        "                q_S_w = np.dot(w_listener, phi_listener)\n",
        "                q_S_A_w = q_S_w[A]\n",
        "                grad_q_S_A_w = phi_listener\n",
        "\n",
        "                if termination or truncation:\n",
        "                    w_listener[A] = w_listener[A] + alpha * (R - q_S_A_w) * grad_q_S_A_w\n",
        "                    continue\n",
        "\n",
        "                max_q_S_A_w = np.max(np.dot(w_listener, phi_next_listener))\n",
        "                w_listener[A] = w_listener[A] + alpha * (R + gamma*max_q_S_A_w - q_S_A_w) * grad_q_S_A_w\n",
        "                phi_listener = phi_next_listener\n",
        "                \n",
        "                # for debug usage\n",
        "                S_listener = S_next_listener\n",
        "    \n",
        "        \n",
        "    return w_speaker, w_listener, R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Returns a initialized weight vector with 0\n",
        "def rand_sl(alpha, gamma, epsilon, num_episode, env):\n",
        "    w_speaker = weight_init((3, 3))\n",
        "    w_listener = weight_init((5, 1131))\n",
        "    R = 0\n",
        "    \n",
        "    for i in range(num_episode):\n",
        "        env.reset()\n",
        "        S_speaker = env.observe('speaker_0')\n",
        "        # encode speaker state\n",
        "        phi_speaker = speaker_encode_state(S_speaker)\n",
        "        \n",
        "        S_listener = env.observe('listener_0')\n",
        "        # encode listener state\n",
        "        phi_listener = listener_encode_state(S_listener)        \n",
        "        \n",
        "        S_next_speaker = None\n",
        "        phi_next_speaker = None\n",
        "        \n",
        "        S_next_listener = None\n",
        "        phi_next_listener = None\n",
        "        \n",
        "        for agent in env.agent_iter():\n",
        "            if agent == 'speaker_0':\n",
        "                if env.truncations[agent] == True or env.terminations[agent] == True:\n",
        "                    env.step(None)\n",
        "                    continue\n",
        "                \n",
        "                # A = eps_greedy_act_selection(epsilon, w_speaker, phi_speaker)\n",
        "                A = env.action_space(agent).sample()\n",
        "                \n",
        "                env.step(A) \n",
        "                _, R, termination, truncation, info = env.last()\n",
        "                \n",
        "                S_next_speaker = env.observe(agent)\n",
        "                #phi_next_speaker = speaker_encode_state(S_next_speaker)\n",
        "                #q_S_w = np.dot(w_speaker, phi_speaker)\n",
        "                #q_S_A_w = q_S_w[A]\n",
        "                #grad_q_S_A_w = phi_speaker\n",
        "\n",
        "                if termination or truncation:\n",
        "                    #w_speaker[A] = w_speaker[A] + alpha * (R - q_S_A_w) * grad_q_S_A_w\n",
        "                    continue\n",
        "\n",
        "                #max_q_S_A_w = np.max(np.dot(w_speaker, phi_next_speaker))\n",
        "                #w_speaker[A] = w_speaker[A] + alpha * (R + gamma*max_q_S_A_w - q_S_A_w) * grad_q_S_A_w\n",
        "                #phi_speaker = phi_next_speaker\n",
        "                \n",
        "                # for debug usage\n",
        "                S_speaker = S_next_speaker\n",
        "                \n",
        "            else:\n",
        "                if env.truncations[agent] == True or env.terminations[agent] == True:\n",
        "                    env.step(None)\n",
        "                    continue\n",
        "                \n",
        "                # A = eps_greedy_act_selection(epsilon, w_listener, phi_listener)\n",
        "                A = env.action_space(agent).sample()\n",
        "\n",
        "                env.step(A)\n",
        "\n",
        "                _, R, termination, truncation, info = env.last()\n",
        "\n",
        "                S_next_listener = env.observe(agent)\n",
        "                #phi_next_listener = listener_encode_state(S_next_listener)\n",
        "\n",
        "                #q_S_w = np.dot(w_listener, phi_listener)\n",
        "                #q_S_A_w = q_S_w[A]\n",
        "                #grad_q_S_A_w = phi_listener\n",
        "\n",
        "                if termination or truncation:\n",
        "                    #w_listener[A] = w_listener[A] + alpha * (R - q_S_A_w) * grad_q_S_A_w\n",
        "                    continue\n",
        "\n",
        "                #max_q_S_A_w = np.max(np.dot(w_listener, phi_next_listener))\n",
        "                #w_listener[A] = w_listener[A] + alpha * (R + gamma*max_q_S_A_w - q_S_A_w) * grad_q_S_A_w\n",
        "                #phi_listener = phi_next_listener\n",
        "                \n",
        "                # for debug usage\n",
        "                S_listener = S_next_listener\n",
        "    \n",
        "        \n",
        "    return R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npE1bpNtLe3P"
      },
      "source": [
        "## Testing Environments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgFbOvAIDojd"
      },
      "source": [
        "### Simple Speaker Listener"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "DlrnfKKHukyd",
        "outputId": "29b2f132-5046-4476-b674-a287194c266a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg from 10 runs:  -8.428359486868654\n"
          ]
        }
      ],
      "source": [
        "result = 0\n",
        "for i in range(10):\n",
        "    episode = 100\n",
        "    env = simple_speaker_listener_v3.env(max_cycles=200, continuous_actions=False)\n",
        "    w_speaker, w_listener, R = q_learning_sl(0.001, 0.99, 0.2, episode, env)\n",
        "    result += R\n",
        "print(\"avg from 10 runs: \", result/10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg from rand 10 runs:  -10.998573154466666\n"
          ]
        }
      ],
      "source": [
        "result = 0\n",
        "for i in range(10):\n",
        "    episode = 100\n",
        "    env = simple_speaker_listener_v3.env(max_cycles=200, continuous_actions=False)\n",
        "    R = rand_sl(0.001, 0.99, 0.2, episode, env)\n",
        "    result += R\n",
        "print(\"avg from rand 10 runs: \", result/10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO-7B65BDojg"
      },
      "source": [
        "### Simple Reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvOEXgrbDojg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnpRcEyFDojg"
      },
      "source": [
        "### Simple World Comm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yezwhg5FLh7T"
      },
      "source": [
        "## Graphing"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
